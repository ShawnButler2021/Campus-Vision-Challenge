{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bodWzNenfX-y",
        "outputId": "e091d781-c754-4f9f-8831-6cd4186110ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch  # PyTorch library for deep learning\n",
        "import torch.nn as nn  # Neural network module in PyTorch\n",
        "from torchvision import models, transforms  # Pre-trained models and image transformations\n",
        "from PIL import Image  # Library for image processing\n",
        "\n",
        "# Dictionary to map class indices to building names\n",
        "class_to_building = {\n",
        "    0: \"Butler Hall\",\n",
        "    1: \"Carpenter Hall\",\n",
        "    2: \"Lee Hall\",\n",
        "    3: \"McCain Hall\",\n",
        "    4: \"McCool Hall\",\n",
        "    5: \"Old Main\",\n",
        "    6: \"Simrall Hall\",\n",
        "    7: \"Student Union\",\n",
        "    8: \"Swalm Hall\",\n",
        "    9: \"Walker Hall\"\n",
        "}\n",
        "\n",
        "# Define the device for computation (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to load a pre-trained model for inference\n",
        "def load_model(num_classes, model_path=\"/content/best_model.pth\"):\n",
        "    # Load a ResNet50 model pre-trained on ImageNet\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Replace the fully connected layer to match the number of classes in our dataset\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    # Load the trained model weights\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
        "\n",
        "    # Move the model to the appropriate device and set it to evaluation mode\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load the model, specifying the number of classes and the path to the saved weights\n",
        "num_classes = 10  # Replace with the actual number of classes in the dataset\n",
        "model = load_model(num_classes, \"/content/best_model.pth\")\n",
        "\n",
        "# Function to preprocess an image for model inference\n",
        "def preprocess_image(image_path, image_size=512):\n",
        "    # Define transformations: resize, convert to tensor, and normalize\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Mean and std for ImageNet\n",
        "    ])\n",
        "\n",
        "    # Open and preprocess the image, converting to RGB format\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension for model input\n",
        "    return image.to(device)\n",
        "\n",
        "# Function to predict the building type given an image\n",
        "def predict(model, image_path, class_to_building):\n",
        "    # Preprocess the image\n",
        "    image = preprocess_image(image_path)\n",
        "\n",
        "    # Make prediction without computing gradients (inference mode)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)  # Get model outputs\n",
        "        probabilities = torch.softmax(outputs, dim=1)  # Convert outputs to probabilities\n",
        "        _, predicted = outputs.max(1)  # Get the class with the highest probability\n",
        "\n",
        "    # Get predicted class index and confidence score\n",
        "    class_idx = predicted.item()\n",
        "    confidence = probabilities[0, class_idx].item()\n",
        "\n",
        "    # Map the class index to the building name\n",
        "    building_name = class_to_building.get(class_idx, \"Unknown Building\")\n",
        "\n",
        "    # Print the prediction and confidence level\n",
        "    print(f\"Predicted Building: {building_name}\")\n",
        "    print(f\"Confidence: {confidence:.4f}\")\n",
        "\n",
        "    return building_name, confidence\n",
        "\n",
        "# New function to predict all images in a folder\n",
        "def predict_folder(model, folder_path, class_to_building):\n",
        "    # Loop through each file in the folder\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        # Construct the full image path\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "        # Check if the file is an image\n",
        "        if image_path.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Predict and print results for each image\n",
        "            building_name, confidence = predict(model, image_path, class_to_building)\n",
        "            print(f\"File: {image_file}, Predicted Building: {building_name}, Confidence: {confidence:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODJX9q7pfzIA",
        "outputId": "5672308c-e280-4a8d-9247-46ba1ff32fd1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-d14726b7781d>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your test images folder\n",
        "test_folder = \"/content/test_images\"  # Replace with the path to your folder in Colab\n",
        "\n",
        "# Run prediction on all images in the folder\n",
        "predict_folder(model, test_folder, class_to_building)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfYGnNLDilnJ",
        "outputId": "5b9092ec-9202-4243-ca4e-03d41a1c8179"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Building: Lee Hall\n",
            "Confidence: 0.9938\n",
            "File: building.jpeg, Predicted Building: Lee Hall, Confidence: 0.9938\n",
            "Predicted Building: Lee Hall\n",
            "Confidence: 0.7370\n",
            "File: building2.jpg, Predicted Building: Lee Hall, Confidence: 0.7370\n"
          ]
        }
      ]
    }
  ]
}